{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training\n",
    "\n",
    "Explain how you split the data into training, testing and validation sets. Explore feature importance. Save the model.\n",
    "\n",
    "\n",
    "\n",
    "We train a LightGBM using a regressor class for each of the 23 study regions on a random sample of 75\\% of the available data (described i) to predict SWE values. Model optimization is specific for each regional model instance and leverages a 5-fold cross-validation grid-search function to identify optimal hyperparameters, including: tree maximum depth, number of leaves, learning rate, subsample fraction, and number of estimators.  We found the model to be most influenced by these hyperparameters with others having insignificant or negative impacts on model performance when changed from the default.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c446eef832ec964573dc49f36fd16bdbed40cbfbefbf557bc2dc78d9e7968689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
